{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy. In the lecture you saw how this was done for the loss but here you will be using accuracy instead.\n",
    "\n",
    "Some notes:\n",
    "\n",
    "Given the architecture of the net, it should succeed in less than 10 epochs.\n",
    "When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\" and stop training.\n",
    "If you add any additional variables, make sure you use the same names as the ones used in the class. This is important for the function signatures (the parameters and names) of the callbacks."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50e721e4c73a69b9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001B[1m11490434/11490434\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# Load the data\n",
    "\n",
    "# Get current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Append data/mnist.npz to the previous path to get the full path\n",
    "\"\"\"\n",
    "  if data is cached in specified path then Tensorflow will use it instead of downloading to specified location. \n",
    "  The _ variable in (x_train, y_train), _ = tf.keras.datasets.mnist.load_data(path=data_path) is used to discard the test set (x_test and y_test) that is normally returned by load_data(). \n",
    "\"\"\"\n",
    "data_path = os.path.join(current_dir, \"data/mnist.npz\")\n",
    "\n",
    "# Discard test set\n",
    "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n",
    "        \n",
    "# Normalize pixel values\n",
    "\"\"\"\n",
    "We do Normalizing on input features, which is an important preprocessing step in ML. Reasons why we have to normalize are:\n",
    "1. Uniform Scale:  Normalizing the data brings all feature values into a similar scale. This is crucial because features with larger scales (e.g., feature A ranges from 0 to 1000 and feature B ranges from 0 to 1) can dominate the learning process and prevent the model from effectively learning from other features.\n",
    "\n",
    "2. Faster Convergence: Normalization helps the optimization algorithm (e.g., gradient descent) converge faster during training. When data is normalized, the optimization process is more efficient and stable, leading to quicker convergence to the optimal solution.\n",
    "\n",
    "3. Better Model Performance: Normalization can lead to improved performance of the model. It can help prevent issues like vanishing or exploding gradients, which are common in deep neural networks with large input feature scales.\n",
    "\n",
    "4. Regularization: Data normalization can be considered a form of regularization. By constraining the range of input values, normalization can reduce overfitting and improve the generalization ability of the model.\n",
    "\n",
    "5. Handling Different Units: When dealing with features that have different units or magnitudes (e.g., weight in kilograms vs. height in centimeters), normalization ensures that the model treats each feature equally regardless of its original scale.\n",
    "\n",
    "6. Compatability with Activation Functions: Some activation functions (e.g., sigmoid, tanh) are sensitive to the scale of input values. Normalizing input data to a specific range (e.g., between 0 and 1 or -1 and 1) can improve the performance of these activation functions.\n",
    "\n",
    "Common Normalization Techniques:\n",
    "1. Min-Max Scaling (Normalization): Scales the data to a fixed range, typically between 0 and 1 or -1 and 1.\n",
    "2. Standardization (Z-score Normalization): Centers the data around zero with unit variance.\n",
    "3. Feature Scaling: Scaling each feature to have a mean of zero and a standard deviation of one.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "x_train = x_train / 255.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T02:05:25.787717Z",
     "start_time": "2024-04-08T02:05:24.488452Z"
    }
   },
   "id": "ddad7877776fc692",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60000 examples with shape (28, 28)\n"
     ]
    }
   ],
   "source": [
    "#Now take a look at the shape of the training data:\n",
    "data_shape = x_train.shape\n",
    "\n",
    "print(f\"There are {data_shape[0]} examples with shape ({data_shape[1]}, {data_shape[2]})\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T02:05:37.658999Z",
     "start_time": "2024-04-08T02:05:37.649801Z"
    }
   },
   "id": "a612e8e40ae75282",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# GRADED CLASS: myCallback\n",
    "### START CODE HERE\n",
    "\n",
    "# Remember to inherit from the correct class\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "        # Define the correct function signature for on_epoch_end\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if logs.get('accuracy') is not None and logs.get('accuracy') > 0.99: # @KEEP\n",
    "                print(\"\\nReached 99% accuracy so cancelling training!\") \n",
    "                \n",
    "                # Stop training once the above condition is met\n",
    "                self.model.stop_training = True\n",
    "\n",
    "### END CODE HERE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T21:03:07.194533Z",
     "start_time": "2024-04-09T21:03:07.142349Z"
    }
   },
   "id": "e695b31190d2fe10",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_mnist\n",
    "def train_mnist(x_train, y_train):\n",
    "\n",
    "    ### START CODE HERE\n",
    "    \n",
    "    # Instantiate the callback class\n",
    "    callbacks = myCallback()\n",
    "    \n",
    "    # Define the model, it should have 3 layers:\n",
    "    # - A Flatten layer that receives inputs with the same shape as the images\n",
    "    # - A Dense layer with 512 units and ReLU activation function\n",
    "    # - A Dense layer with 10 units and softmax activation function\n",
    "    model = tf.keras.models.Sequential([ \n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ]) \n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy']) \n",
    "    \n",
    "    # Fit the model for 10 epochs adding the callbacks\n",
    "    # and save the training history\n",
    "    history = model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
    "\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T21:11:05.098633Z",
     "start_time": "2024-04-09T21:11:05.026293Z"
    }
   },
   "id": "dc5b5625196d307",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 4ms/step - accuracy: 0.8988 - loss: 0.3401\n",
      "Epoch 2/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.9752 - loss: 0.0807\n",
      "Epoch 3/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9841 - loss: 0.0508\n",
      "Epoch 4/10\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 4ms/step - accuracy: 0.9888 - loss: 0.0341\n",
      "Epoch 5/10\n",
      "\u001B[1m1869/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9915 - loss: 0.0255\n",
      "Reached 99% accuracy so cancelling training!\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 4ms/step - accuracy: 0.9915 - loss: 0.0255\n"
     ]
    }
   ],
   "source": [
    "hist = train_mnist(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T21:12:16.691468Z",
     "start_time": "2024-04-09T21:11:31.180015Z"
    }
   },
   "id": "2c323f72cca60975",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "38eb4e050a38c696"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
